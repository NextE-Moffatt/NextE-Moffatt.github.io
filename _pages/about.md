---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Fei Meng, currently focusing on Natural Language Processing (NLP) research. My research interests include:
- Large Language Models
- Multimodal Learning
<!-- - Machine Translation -->
<!-- - Dialogue Systems -->
- Reinforcement Learning
<!-- - Meta Learning -->

<span class='anchor' id='news'></span>

# üî• News

- *2024.04*: &nbsp;üìù Updated [research log](/research-log) with recent experimental progress
- *2024.04*: &nbsp;üéâ Personal academic homepage launched

<span class='anchor' id='publications'></span>

# üìù Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2024</div><img src='../images/paper1.png' alt="paper1" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Large Language Models for Dialogue Systems](/llm-dialogue)

**Author 1**, Author 2, Author 3

[**PDF**](https://arxiv.org/pdf/xxxx.xxxxx.pdf) \| [**Code**](https://github.com/username/project) \| [**Project Page**](https://username.github.io/project) \| [**Video**](https://www.youtube.com/watch?v=xxx)

- Proposed a novel dialogue system framework based on large language models
- Achieved state-of-the-art results on multiple public datasets
- Released open-source code with wide adoption
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2023</div><img src='../images/paper2.png' alt="paper2" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multimodal Learning for Machine Translation](/multimodal-mt)

**Author 1**, Author 2, Author 3

[**PDF**](https://arxiv.org/pdf/yyyy.yyyyy.pdf) \| [**Code**](https://github.com/username/project2)

- Introduced a novel multimodal learning framework for machine translation
- Significantly improved translation quality, especially for visual scene-related text
</div>
</div>

# üìö More Publications

- [Reinforcement Learning for Dialogue Systems](/papers/rl-dialogue/), **Author 1**, Author 2, Author 3, *ICLR 2023*
- [Meta Learning for Few-shot Learning](/papers/meta-learning/), **Author 1**, Author 2, *AAAI 2023*

<span class='anchor' id='honors'></span>

# üéñ Honors and Awards

- *2024* Outstanding Graduate Student Award, Tsinghua University
- *2023* Best Paper Award, Conference Name

<span class='anchor' id='education'></span>

<!-- # üìñ Education

- *2021 - 2024*, Tsinghua University
- *2013 - 2017*, Xi'an University of Technology -->

<span class='anchor' id='talks'></span>

# üí¨ Invited Talks

- *2024.03*, Recent Advances in LLMs, Conference/Institution name
- *2023.09*, Multimodal Learning Applications, Conference/Institution name

<span class='anchor' id='internships'></span>

# üíª Internships

- *2023.09 - 2024.03*, Tsinghua AIR, Research Intern, AI Research Lab